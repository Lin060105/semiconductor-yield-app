import streamlit as st
import pandas as pd
import numpy as np
from pycaret.classification import load_model, predict_model
import shap
import matplotlib.pyplot as plt
import os

# --- 1. è¨­å®šé é¢è³‡è¨Š (ç§»é™¤å´é‚Šæ¬„å¾Œï¼ŒLayout æ›´é‡è¦) ---
st.set_page_config(
    page_title="Semiconductor Yield Prediction",
    page_icon="ğŸ§Š",
    layout="wide",
    initial_sidebar_state="collapsed" # é è¨­æ”¶èµ·å´é‚Šæ¬„
)

# --- 2. è¼‰å…¥æ¨¡å‹ (é‚è¼¯ç§»å‡ºå´é‚Šæ¬„) ---
# è¨­å®šæ¨¡å‹è·¯å¾‘
model_path = 'output/final_yield_prediction_model'

@st.cache_resource
def load_yield_model():
    """è¼‰å…¥æ¨¡å‹ä¸¦å›å‚³ Pipeline"""
    if os.path.exists(model_path + '.pkl'):
        return load_model(model_path)
    else:
        return None

# åœ¨ä¸»æµç¨‹ä¸­è¼‰å…¥æ¨¡å‹
with st.spinner("Loading AI Model and Resources..."):
    pipeline = load_yield_model()

# æª¢æŸ¥æ¨¡å‹æ˜¯å¦è¼‰å…¥æˆåŠŸï¼Œä¸¦è¨­å®š model è®Šæ•¸
if pipeline is None:
    st.error(f"âŒ Critical Error: Model file not found at '{model_path}.pkl'. Please run training scripts first.")
    st.stop() # åœæ­¢åŸ·è¡Œå¾ŒçºŒç¨‹å¼ç¢¼
else:
    # å˜—è©¦æå–æœ€çµ‚æ¨¡å‹ä¾› SHAP ä½¿ç”¨
    try:
        model = pipeline._final_estimator
    except:
        model = pipeline

# --- 3. æ¨™é¡Œèˆ‡ç°¡ä»‹ (æ•´åˆç‹€æ…‹é¡¯ç¤º) ---
st.title("ğŸ§Š AI Semiconductor Yield Prediction System")

# ä½¿ç”¨ Columns ä¾†è®“ç‹€æ…‹é¡¯ç¤ºæ›´ç·Šæ¹Š
col_desc, col_status = st.columns([3, 1])
with col_desc:
    st.markdown("""
    **Overview**: This application predicts wafer yield outcomes and analyzes failure root causes using SHAP values.
    Upload your batch data to identify high-risk wafers immediately.
    """)
with col_status:
    # ç”¨ä¸€å€‹æ¼‚äº®çš„ç¶ è‰²å€å¡Šé¡¯ç¤ºç‹€æ…‹ï¼Œå–ä»£åŸæœ¬çš„å´é‚Šæ¬„
    st.success("âœ… System Status: Online\n\nModel: CatBoost/XGBoost Ensemble")

st.markdown("---")

# --- 4. ä¸»åŠŸèƒ½åˆ†é  (UI è‹±æ–‡çµ±ä¸€) ---
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“‚ Batch Prediction", 
    "ğŸ“Š Statistics", 
    "âš ï¸ Fail Ranking", 
    "ğŸ” Root Cause (SHAP)",
    "ğŸ“‰ Model Performance" 
])

# åˆå§‹åŒ– session_state
if 'predictions' not in st.session_state:
    st.session_state['predictions'] = None
if 'data' not in st.session_state:
    st.session_state['data'] = None

# ==========================================
# Tab 1: Batch Prediction
# ==========================================
with tab1:
    st.subheader("Data Upload & Execution")
    
    col_input, col_action = st.columns([2, 1])
    
    with col_input:
        use_sample = st.checkbox("Use Sample Data (secom_processed.csv)")
        uploaded_file = st.file_uploader("Or Upload CSV File", type=['csv'])
    
    df = None
    if use_sample:
        if os.path.exists('data/secom_processed.csv'):
            df = pd.read_csv('data/secom_processed.csv').head(100)
            st.info("â„¹ï¸ Loaded sample data (first 100 rows).")
    elif uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        st.success("âœ… File uploaded successfully.")

    if df is not None:
        st.session_state['data'] = df
        
        # æŠŠæŒ‰éˆ•æ”¾åœ¨å³å´ Action å€å¡Šï¼Œæ¯”è¼ƒæ•´é½Š
        with col_action:
            st.write("###") #ç”¨ä¾†å°é½Šçš„ç©ºç™½
            if st.button("ğŸš€ Run Prediction", type="primary", use_container_width=True):
                with st.spinner("Processing wafers..."):
                    predictions = predict_model(pipeline, data=df)
                    st.session_state['predictions'] = predictions
                    st.success("Analysis Complete!")
        
        with st.expander("ğŸ‘ï¸ Preview Input Data"):
            st.dataframe(df.head())

        # ä¸‹è¼‰æŒ‰éˆ•å€åŸŸ
        if st.session_state['predictions'] is not None:
            st.divider()
            st.subheader("Downloads")
            csv_all = st.session_state['predictions'].to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ Download Full Results (CSV)",
                data=csv_all,
                file_name="full_predictions_result.csv",
                mime="text/csv"
            )

# ==========================================
# Tab 2: Batch Statistics
# ==========================================
with tab2:
    st.subheader("Yield Overview")
    if st.session_state['predictions'] is not None:
        preds = st.session_state['predictions']
        total = len(preds)
        fail_count = preds[preds['prediction_label'] == 1].shape[0]
        pass_count = total - fail_count
        yield_rate = (pass_count / total) * 100
        
        c1, c2, c3 = st.columns(3)
        c1.metric("Total Wafers", f"{total}")
        c2.metric("Yield Rate", f"{yield_rate:.2f}%")
        c3.metric("Defect Count", f"{fail_count}", delta_color="inverse")
        
        # è®“åœ–è¡¨ç½®ä¸­ä¸”ä¸è¦å¤ªå¤§
        col_fig, _ = st.columns([1, 1])
        with col_fig:
            fig, ax = plt.subplots(figsize=(6, 4))
            ax.pie([pass_count, fail_count], labels=['Pass', 'Fail'], autopct='%1.1f%%', colors=['#66b3ff','#ff9999'])
            st.pyplot(fig)
    else:
        st.warning("âš ï¸ Please run prediction in the 'Batch Prediction' tab first.")

# ==========================================
# Tab 3: Fail Ranking
# ==========================================
with tab3:
    st.subheader("High-Risk Wafer Ranking")
    if st.session_state['predictions'] is not None:
        preds = st.session_state['predictions']
        fails = preds[preds['prediction_label'] == 1].copy()
        
        if not fails.empty:
            st.markdown("**Top 20 Wafers with Highest Failure Probability:**")
            top_fails = fails.sort_values(by='prediction_score', ascending=False).head(20)
            st.dataframe(top_fails.style.background_gradient(subset=['prediction_score'], cmap='Reds'))
            
            csv_fails = top_fails.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸš¨ Download Top 20 High-Risk List (CSV)",
                data=csv_fails,
                file_name="high_risk_wafers.csv",
                mime="text/csv",
                type="primary"
            )
        else:
            st.success("ğŸ‰ No failures predicted in this batch!")
            st.divider()
            st.markdown("**Lowest Confidence 'Pass' Wafers (Watch List):**")
            risky_pass = preds[preds['prediction_label'] == 0].sort_values(by='prediction_score', ascending=True).head(10)
            st.dataframe(risky_pass)
            
            csv_risky = risky_pass.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ Download Watch List (CSV)",
                data=csv_risky,
                file_name="risky_pass_wafers.csv",
                mime="text/csv"
            )
    else:
        st.warning("âš ï¸ Please run prediction first.")

# ==========================================
# Tab 4: SHAP Analysis 
# ==========================================
with tab4:
    st.subheader("Model Interpretability")
    
    st.markdown("### 1. Global Feature Importance")
    st.caption("Visualizes which sensor readings contribute most to yield failures across the entire dataset.")
    
    shap_img_path = "reports/SHAP Summary.png"
    
    if os.path.exists(shap_img_path):
        st.image(shap_img_path, caption="SHAP Summary Plot", use_container_width=True)
    else:
        st.info(f"SHAP Summary image not found at `{shap_img_path}`.")

    st.divider()
    st.markdown("### 2. Local Waterfall Analysis")
    st.caption("Deep dive into a specific wafer to understand why the model predicted it as Fail/Pass.")
    
    if st.session_state['data'] is not None:
        shap_data = st.session_state['data'].head(500) # Limit for performance
        
        # é¸æ“‡æ™¶åœ“ ID
        col_sel, col_viz = st.columns([1, 3])
        
        with col_sel:
            sample_idx = st.selectbox("Select Wafer Index:", shap_data.index)
            
        with col_viz:
            try:
                # æº–å‚™ SHAP è³‡æ–™
                transformer = pipeline[:-1]
                X_transformed = transformer.transform(shap_data)
                explainer = shap.TreeExplainer(model)
                shap_values = explainer.shap_values(X_transformed)
                
                # è™•ç† SHAP æ ¼å¼ (ç›¸å®¹ XGBoost/CatBoost)
                if isinstance(shap_values, list):
                    sv = shap_values[1]
                    bv = explainer.expected_value[1] if isinstance(explainer.expected_value, (list, np.ndarray)) else explainer.expected_value
                elif len(np.array(shap_values).shape) == 3:
                    sv = np.array(shap_values)[:, :, 1]
                    bv = explainer.expected_value[1] if isinstance(explainer.expected_value, (list, np.ndarray)) else explainer.expected_value
                else:
                    sv = shap_values
                    bv = explainer.expected_value
                    if isinstance(bv, (list, np.ndarray)) and len(bv) == 1:
                        bv = bv[0]
                
                loc_idx = shap_data.index.get_loc(sample_idx)
                row_data = X_transformed.iloc[loc_idx] if isinstance(X_transformed, pd.DataFrame) else X_transformed[loc_idx]
                
                explanation = shap.Explanation(
                    values=sv[loc_idx], 
                    base_values=bv, 
                    data=row_data, 
                    feature_names=X_transformed.columns if hasattr(X_transformed, 'columns') else None
                )
                
                st.markdown(f"**Impact Factors for Wafer {sample_idx}:**")
                fig_water, ax_water = plt.subplots()
                shap.plots.waterfall(explanation, show=False)
                st.pyplot(fig_water)
                
            except Exception as e:
                st.error(f"Error generating SHAP plot: {e}")
    else:
        st.warning("âš ï¸ Please load data first in the 'Batch Prediction' tab.")

# ==========================================
# Tab 5: Model Performance 
# ==========================================
with tab5:
    st.subheader("Validation Metrics")
    st.markdown("Detailed proof of model reliability.")
    
    report_imgs = {
        "Confusion Matrix": "output/automl_reports/confusion_matrix.png",
        "AUC-ROC Curve": "output/automl_reports/auc_roc_curve.png",
        "Feature Importance": "output/automl_reports/feature_importance.png",
        "Learning Curve": "output/automl_reports/learning_curve.png",
        "Model Comparison": "reports/model_comparison_final.png"
    }

    col1, col2 = st.columns(2)
    
    for i, (title, path) in enumerate(report_imgs.items()):
        container = col1 if i % 2 == 0 else col2
        with container:
            if os.path.exists(path):
                st.image(path, caption=title, use_container_width=True)
            else:
                st.warning(f"âš ï¸ Missing: {title}")
    
    st.divider()
    st.subheader("Overfitting Analysis")
    analysis_path = "reports/overfitting_analysis.txt"
    if os.path.exists(analysis_path):
        with open(analysis_path, "r", encoding='utf-8') as f:
            report_text = f.read()
        st.text_area("Analysis Report", report_text, height=150)
    else:
        st.info("No analysis report found.")
