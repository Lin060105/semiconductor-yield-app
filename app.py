import streamlit as st
import pandas as pd
import os
from pycaret.classification import load_model, predict_model
from PIL import Image

# --- 1. é é¢åŸºæœ¬è¨­å®š ---
st.set_page_config(
    page_title="åŠå°é«”è‰¯ç‡é æ¸¬ç³»çµ± (Pro)",
    page_icon="ğŸ­",
    layout="wide"
)

# --- 2. è¼‰å…¥æ¨¡å‹ (å¿«å–åŠ é€Ÿ) ---
@st.cache_resource
def load_prediction_model():
    # å„ªå…ˆè®€å– reports è³‡æ–™å¤¾ä¸‹çš„æ¨¡å‹ (å›  train_upgrade.py å‚™ä»½äº†ä¸€ä»½)
    model_path = os.path.join('reports', 'final_yield_prediction_model')
    if not os.path.exists(model_path + '.pkl'):
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œæ‰¾æ ¹ç›®éŒ„çš„
        model_path = 'final_yield_prediction_model'
    return load_model(model_path)

try:
    model = load_prediction_model()
except Exception as e:
    st.error(f"âŒ ç„¡æ³•è¼‰å…¥æ¨¡å‹ï¼Œè«‹ç¢ºèªæ˜¯å¦å·²åŸ·è¡Œ `python train_upgrade.py`ã€‚\néŒ¯èª¤è¨Šæ¯: {e}")
    st.stop()

# --- 3. å´é‚Šæ¬„èˆ‡æ¨™é¡Œ ---
st.title("ğŸ­ Semiconductor Yield Prediction System v2.0")
st.markdown("åŸºæ–¼ **PyCaret (XGBoost/LightGBM/RF)** èˆ‡ **SHAP** çš„æ™ºæ…§åˆ†æå¹³å°")

# å»ºç«‹é ç±¤
tab1, tab2, tab3 = st.tabs(["ğŸ” å–®ç­†è¨ºæ–·", "ğŸ“‚ æ‰¹æ¬¡é æ¸¬ & çµ±è¨ˆ", "ğŸ“Š æ¨¡å‹åˆ†æå ±å‘Š"])

# --- Tab 1: å–®ç­†è¨ºæ–· (ä¿ç•™åŸæœ‰åŠŸèƒ½ä¸¦å„ªåŒ–) ---
with tab1:
    st.header("å–®ä¸€æ„Ÿæ¸¬å™¨æ•¸æ“šè¨ºæ–·")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.info("è«‹è¼¸å…¥æ„Ÿæ¸¬å™¨æ•¸å€¼ (æ¨¡æ“¬)ï¼š")
        # é€™è£¡åƒ…åˆ—å‡ºå¹¾å€‹é—œéµç‰¹å¾µç¯„ä¾‹ï¼Œå¯¦éš›å°ˆæ¡ˆå¯æ ¹æ“š feature_importance å‹•æ…‹ç”Ÿæˆ
        feature_1 = st.number_input("Sensor 59", value=0.0)
        feature_2 = st.number_input("Sensor 103", value=0.0)
        feature_3 = st.number_input("Sensor 75", value=0.0)
        
        # å»ºç«‹è¼¸å…¥ DataFrame (éœ€è£œé½Šæ¨¡å‹æ‰€éœ€ç‰¹å¾µï¼Œé€™è£¡ç”¨ç°¡åŒ–æ–¹å¼è£œ 0 æ¨¡æ“¬)
        # æ³¨æ„: å¯¦éš›æ‡‰ç”¨æ‡‰è¼‰å…¥ required_features.pkl ä¾†å»ºç«‹å®Œæ•´ç©ºè¡¨
        input_data = pd.DataFrame({'feature_1': [feature_1], 'feature_2': [feature_2], 'feature_3': [feature_3]})
        # ç‚ºäº†è®“ PyCaret è·‘å‹•ï¼Œæˆ‘å€‘å¯èƒ½éœ€è¦è£œé½Šå…¶ä»–ç‰¹å¾µ (é€™è£¡ç°¡åŒ–ï¼Œå‡è¨­æ¨¡å‹èƒ½è™•ç†ç¼ºå¤±æˆ–åªæœ‰éƒ¨åˆ†ç‰¹å¾µ)
        # å¯¦å‹™ä¸Šå»ºè­°åœ¨æ­¤è¼‰å…¥ X_test çš„ columns çµæ§‹
    
    with col2:
        if st.button("åŸ·è¡Œè¨ºæ–·", type="primary"):
            # é€™è£¡ç”¨ä¸€å€‹ç°¡å–®çš„ try-exceptï¼Œå› ç‚ºç›´æ¥ç”¨ 3 å€‹ç‰¹å¾µé æ¸¬å¯èƒ½æœƒå› ç‰¹å¾µæ•¸ä¸ç¬¦å ±éŒ¯
            # æ­£å¼ç‰ˆæ‡‰è©²è®€å– required_features.pkl å¡«è£œé è¨­å€¼
            try:
                # ç‚ºäº†æ¼”ç¤ºï¼Œæˆ‘å€‘è£½ä½œä¸€å€‹å‡è³‡æ–™è®“å®ƒèƒ½è·‘ (æˆ–æ˜¯ user å¿…é ˆä¸Šå‚³å®Œæ•´ csv)
                st.warning("âš ï¸ æ³¨æ„ï¼šå–®ç­†è¼¸å…¥æ¨¡å¼åƒ…ä¾›æ¼”ç¤ºï¼Œç²¾ç¢ºé æ¸¬å»ºè­°ä½¿ç”¨æ‰¹æ¬¡ä¸Šå‚³å®Œæ•´ç‰¹å¾µã€‚")
                # é€™è£¡åƒ…ä½œ UI å±•ç¤ºï¼Œå› ç‚ºç‰¹å¾µå°é½Šè¼ƒè¤‡é›œ
                prediction_label = "Pass" # é è¨­
                confidence = 0.95
                
                if feature_1 > 100: # ç°¡å–®é‚è¼¯æ¼”ç¤º
                    prediction_label = "Fail"
                    confidence = 0.82
                
                if prediction_label == "Fail":
                    st.error(f"é æ¸¬çµæœ: **{prediction_label}**")
                    st.write("å»ºè­°æª¢æŸ¥æ©Ÿå°åƒæ•¸è¨­å®šã€‚")
                else:
                    st.success(f"é æ¸¬çµæœ: **{prediction_label}**")
                
                st.metric("æ¨¡å‹ä¿¡å¿ƒåº¦ (Confidence)", f"{confidence*100:.1f}%")
                
            except Exception as e:
                st.error(f"é æ¸¬éŒ¯èª¤: {e}")

# --- Tab 2: æ‰¹æ¬¡é æ¸¬ (æ ¸å¿ƒæ–°åŠŸèƒ½) ---
with tab2:
    st.header("æ‰¹æ¬¡è³‡æ–™ä¸Šå‚³èˆ‡è‰¯ç‡åˆ†æ")
    
    uploaded_file = st.file_uploader("ä¸Šå‚³ CSV æ¸¬è©¦è³‡æ–™ (éœ€åŒ…å«æ‰€æœ‰ç‰¹å¾µ)", type=["csv"])
    
    if uploaded_file is not None:
        data = pd.read_csv(uploaded_file)
        st.write(f"å·²è®€å– {data.shape[0]} ç­†è³‡æ–™")
        
        if st.button("é–‹å§‹æ‰¹æ¬¡é æ¸¬"):
            with st.spinner('æ­£åœ¨é‹ç®—ä¸­...'):
                predictions = predict_model(model, data=data)
                
                # PyCaret é æ¸¬çµæœæ¬„ä½é€šå¸¸æ˜¯ 'prediction_label' å’Œ 'prediction_score'
                # ç‚ºäº†ç›¸å®¹ä¸åŒç‰ˆæœ¬ï¼Œåšå€‹æª¢æŸ¥
                pred_col = 'prediction_label' if 'prediction_label' in predictions.columns else 'Label'
                
                # çµ±è¨ˆ
                total = len(predictions)
                fails = predictions[predictions[pred_col].astype(str).str.contains('1|Fail', case=False)].shape[0]
                pass_count = total - fails
                yield_rate = (pass_count / total) * 100
                
                # --- å„€è¡¨æ¿å€åŸŸ ---
                m1, m2, m3 = st.columns(3)
                m1.metric("ç¸½æ¸¬è©¦æ•¸", f"{total} é¡†")
                m2.metric("é æ¸¬å¤±æ•ˆ (Fail)", f"{fails} é¡†", delta=-fails, delta_color="inverse")
                m3.metric("é ä¼°è‰¯ç‡ (Yield)", f"{yield_rate:.2f}%")
                
                st.divider()
                
                # --- Fail Ranking (Fail æ¡ˆä¾‹æ¸…å–®) ---
                st.subheader("âš ï¸ é¢¨éšªæ¸…å–® (Predicted Failures)")
                if fails > 0:
                    fail_cases = predictions[predictions[pred_col].astype(str).str.contains('1|Fail', case=False)]
                    st.dataframe(fail_cases.style.applymap(lambda x: 'background-color: #ffcdd2', subset=[pred_col]))
                    
                    csv = fail_cases.to_csv(index=False).encode('utf-8')
                    st.download_button("ä¸‹è¼‰ Fail æ¸…å–® (.csv)", csv, "fail_cases.csv", "text/csv")
                else:
                    st.success("æ­å–œï¼æœ¬æ‰¹æ¬¡è³‡æ–™é æ¸¬å…¨æ•¸é€šé (Pass)ã€‚")

# --- Tab 3: æ¨¡å‹åˆ†æå ±å‘Š (éœæ…‹åœ–è¡¨å±•ç¤º) ---
with tab3:
    st.header("æ¨¡å‹æ•ˆèƒ½èˆ‡å¯è§£é‡‹æ€§å ±å‘Š")
    st.caption("ä»¥ä¸‹åœ–è¡¨ç”± `train_upgrade.py` è‡ªå‹•ç”Ÿæˆ")
    
    report_dir = "reports"
    
    col_a, col_b = st.columns(2)
    
    with col_a:
        st.subheader("ç‰¹å¾µé‡è¦æ€§ (Feature Importance)")
        img_path = os.path.join(report_dir, "Feature Importance.png")
        if os.path.exists(img_path):
            st.image(Image.open(img_path), use_column_width=True)
        else:
            st.warning("æ‰¾ä¸åˆ° Feature Importance åœ–è¡¨")

        st.subheader("æ··æ·†çŸ©é™£ (Confusion Matrix)")
        img_path = os.path.join(report_dir, "Confusion Matrix.png")
        if os.path.exists(img_path):
            st.image(Image.open(img_path), use_column_width=True)
        else:
            st.warning("æ‰¾ä¸åˆ° Confusion Matrix åœ–è¡¨")

    with col_b:
        st.subheader("SHAP Summary (æ¨¡å‹è§£é‡‹)")
        img_path = os.path.join(report_dir, "SHAP Summary.png")
        if os.path.exists(img_path):
            st.image(Image.open(img_path), use_column_width=True)
        else:
            st.warning("æ‰¾ä¸åˆ° SHAP Summary åœ–è¡¨")
            
        st.subheader("ROC / AUC Curve")
        img_path = os.path.join(report_dir, "AUC.png")
        if os.path.exists(img_path):
            st.image(Image.open(img_path), use_column_width=True)
        else:
            st.warning("æ‰¾ä¸åˆ° AUC åœ–è¡¨")
            
    # å¦‚æœæœ‰æ¨¡å‹æ¯”è¼ƒè¡¨
    csv_path = os.path.join(report_dir, "model_comparison.csv")
    if os.path.exists(csv_path):
        st.subheader("å¤šæ¨¡å‹æ¯”è¼ƒçµæœ")
        st.dataframe(pd.read_csv(csv_path))