import streamlit as st
import pandas as pd
import numpy as np
import os
import pickle
from pycaret.classification import load_model, predict_model
import matplotlib.pyplot as plt

# --- 1. é é¢è¨­å®š ---
st.set_page_config(
    page_title="Semiconductor Yield Prediction Pro",
    page_icon="ğŸ­",
    layout="wide"
)

st.title("ğŸ­ åŠå°é«”è‰¯ç‡é æ¸¬ç³»çµ± (v2.0 Pro)")
st.markdown("""
æœ¬ç³»çµ±åˆ©ç”¨ **CatBoost / Random Forest** æ•´åˆæ¨¡å‹é æ¸¬æ™¶ç‰‡è‰¯ç‡ (Pass/Fail)ã€‚
ä¸¦æä¾›æ¨¡å‹è§£é‡‹ (SHAP) èˆ‡å¤šæ¨¡å‹æ•ˆèƒ½æ¯”è¼ƒå ±å‘Šã€‚
""")

# --- 2. è¼‰å…¥æ¨¡å‹èˆ‡è³‡æº ---
@st.cache_resource
def load_prediction_model():
    # å„ªå…ˆè¼‰å…¥æ–°çš„æœ€ä½³æ¨¡å‹ï¼Œè‹¥ç„¡å‰‡è¼‰å…¥èˆŠçš„
    if os.path.exists('final_yield_prediction_model.pkl'):
        return load_model('final_yield_prediction_model')
    elif os.path.exists('reports/final_yield_prediction_model.pkl'):
        return load_model('reports/final_yield_prediction_model')
    else:
        st.error("âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆï¼Œè«‹å…ˆåŸ·è¡Œ train_upgrade.py")
        return None

model = load_prediction_model()

# è¼‰å…¥ç‰¹å¾µæ¸…å–® (ç¢ºä¿è¼¸å…¥é †åºæ­£ç¢º)
try:
    if os.path.exists('required_features.pkl'):
        with open('required_features.pkl', 'rb') as f:
            required_features = pickle.load(f)
    else:
        st.warning("âš ï¸ æ‰¾ä¸åˆ° required_features.pklï¼Œå°‡ä½¿ç”¨é è¨­ç‰¹å¾µã€‚")
        required_features = [f'Sensor_{i}' for i in range(1, 11)]
except Exception as e:
    st.error(f"âš ï¸ è¼‰å…¥ç‰¹å¾µæ¸…å–®å¤±æ•—: {e}")
    required_features = [f'Sensor_{i}' for i in range(1, 11)]

# --- 3. å»ºç«‹åˆ†é  ---
tab1, tab2, tab3 = st.tabs(["ğŸ” å–®é»/æ‰¹æ¬¡é æ¸¬", "ğŸ“Š æ¨¡å‹è§£é‡‹ (SHAP)", "ğŸ† æ¨¡å‹æ•ˆèƒ½å ±å‘Š"])

# === Tab 1: é æ¸¬åŠŸèƒ½ ===
with tab1:
    st.header("ç·šä¸Šé æ¸¬èˆ‡æ¨¡æ“¬")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("è¼¸å…¥æ„Ÿæ¸¬å™¨æ•¸å€¼")
        input_data = {}
        # ç‚ºäº†æ¼”ç¤ºï¼Œåªé¡¯ç¤ºå‰ 5 å€‹ç‰¹å¾µçš„è¼¸å…¥æ¡†
        display_features = required_features[:5] if len(required_features) > 5 else required_features
        for feature in display_features:
            val = st.number_input(f"{feature}", value=0.0)
            input_data[feature] = val
        
        if len(required_features) > 5:
            st.caption(f"*(å·²éš±è—å‰©é¤˜ {len(required_features)-5} å€‹ç‰¹å¾µï¼Œé è¨­ç‚º 0)*")
            # å…¶ä»–ç‰¹å¾µè£œ 0 (æ¨¡æ“¬)
            for feature in required_features[5:]:
                input_data[feature] = 0.0
            
        predict_btn = st.button("ğŸš€ åŸ·è¡Œé æ¸¬", type="primary")

    with col2:
        st.subheader("é æ¸¬çµæœ")
        if predict_btn and model:
            try:
                df_input = pd.DataFrame([input_data])
                prediction = predict_model(model, data=df_input)
                
                # PyCaret 3.x è¼¸å‡ºæ¬„ä½è™•ç†
                label_col = 'prediction_label' if 'prediction_label' in prediction.columns else 'Label'
                score_col = 'prediction_score' if 'prediction_score' in prediction.columns else 'Score'
                
                if label_col in prediction.columns:
                    result = prediction[label_col].iloc[0]
                    score = prediction[score_col].iloc[0]
                    
                    # å‡è¨­ 1 æˆ– '1' ç‚º Fail
                    if str(result) == '1' or result == 1: 
                        st.error(f"âš ï¸ é æ¸¬çµæœ: **Fail (ç•°å¸¸)**")
                        st.metric("ç•°å¸¸æ©Ÿç‡ (Confidence)", f"{score:.2%}")
                        st.warning("å»ºè­°è¡Œå‹•ï¼šæª¢æŸ¥ Sensor æ•¸å€¼æ˜¯å¦åé›¢è£½ç¨‹è¦ç¯„ã€‚")
                    else:
                        st.success(f"âœ… é æ¸¬çµæœ: **Pass (æ­£å¸¸)**")
                        st.metric("ä¿¡å¿ƒæ°´æº–", f"{score:.2%}")
                else:
                    st.error("ç„¡æ³•è§£æé æ¸¬çµæœï¼Œæ¬„ä½åç¨±ä¸ç¬¦ã€‚")
                    st.write(prediction.columns)
            except Exception as e:
                st.error(f"é æ¸¬åŸ·è¡ŒéŒ¯èª¤: {e}")

        st.markdown("---")
        st.subheader("ğŸ“‚ æ‰¹æ¬¡ä¸Šå‚³é æ¸¬")
        uploaded_file = st.file_uploader("ä¸Šå‚³ CSV æª”æ¡ˆ (éœ€åŒ…å«æ‰€æœ‰æ„Ÿæ¸¬å™¨æ¬„ä½)", type="csv")
        if uploaded_file and model:
            try:
                batch_df = pd.read_csv(uploaded_file)
                # æª¢æŸ¥é—œéµæ¬„ä½æ˜¯å¦å­˜åœ¨
                missing_cols = [col for col in required_features if col not in batch_df.columns]
                
                if not missing_cols:
                    predictions = predict_model(model, data=batch_df)
                    st.success("âœ… æ‰¹æ¬¡é æ¸¬å®Œæˆï¼")
                    st.write(predictions.head())
                    
                    # ä¸‹è¼‰çµæœ
                    csv = predictions.to_csv(index=False).encode('utf-8')
                    st.download_button("ğŸ“¥ ä¸‹è¼‰é æ¸¬çµæœ", csv, "predictions.csv", "text/csv")
                else:
                    st.error(f"âŒ æª”æ¡ˆç¼ºå°‘ä»¥ä¸‹æ¬„ä½: {missing_cols[:3]}...")
            except Exception as e:
                st.error(f"æª”æ¡ˆè®€å–å¤±æ•—: {e}")

# === Tab 2: æ¨¡å‹è§£é‡‹ (SHAP) ===
with tab2:
    st.header("ğŸ§  æ¨¡å‹è§£é‡‹ï¼šç‚ºä»€éº¼æœƒ Failï¼Ÿ")
    st.info("æ­¤é é¢å±•ç¤º SHAP (SHapley Additive exPlanations) åˆ†æï¼Œå¹«åŠ©å·¥ç¨‹å¸«ç†è§£å“ªäº›æ„Ÿæ¸¬å™¨æ•¸å€¼å°è‰¯ç‡å½±éŸ¿æœ€å¤§ã€‚")
    
    # é¡¯ç¤ºéœæ…‹ç”Ÿæˆçš„ SHAP åœ–
    shap_img_path = os.path.join("reports", "SHAP Summary.png")
    if os.path.exists(shap_img_path):
        st.image(shap_img_path, caption="å…¨åŸŸç‰¹å¾µé‡è¦æ€§ (Global Feature Importance)", use_column_width=True)
    else:
        st.warning("âš ï¸ å°šæœªç”Ÿæˆ SHAP Summary åœ–è¡¨ã€‚è«‹ç¢ºèª train_upgrade.py å·²å®Œæ•´åŸ·è¡Œã€‚")
        
    st.markdown("### ğŸ’¡ å¦‚ä½•è§£è®€ï¼Ÿ")
    st.markdown("""
    - **ç‰¹å¾µæ’åº**ï¼šç”±ä¸Šè€Œä¸‹ä»£è¡¨å½±éŸ¿åŠ›ç”±å¤§åˆ°å°ã€‚
    - **é¡è‰²**ï¼šç´…è‰²ä»£è¡¨æ•¸å€¼è¼ƒé«˜ï¼Œè—è‰²ä»£è¡¨æ•¸å€¼è¼ƒä½ã€‚
    - **SHAP Value**ï¼šå‘å³åä»£è¡¨å¢åŠ  Fail æ©Ÿç‡ï¼Œå‘å·¦åä»£è¡¨å¢åŠ  Pass æ©Ÿç‡ã€‚
    """)

# === Tab 3: æ¨¡å‹æ•ˆèƒ½å ±å‘Š ===
with tab3:
    st.header("ğŸ† å¤šæ¨¡å‹è©•ä¼°å ±å‘Š")
    
    # 1. é¡¯ç¤ºæ¯”è¼ƒè¡¨æ ¼
    csv_path = os.path.join("reports", "model_comparison.csv")
    if os.path.exists(csv_path):
        st.subheader("æ¨¡å‹æŒ‡æ¨™æ’è¡Œæ¦œ")
        df_metrics = pd.read_csv(csv_path)
        st.dataframe(df_metrics.style.highlight_max(axis=0, subset=['AUC', 'Recall', 'F1'], color='lightgreen'))
        st.caption("è¨»ï¼šRecall (å¬å›ç‡) å°æ–¼åµæ¸¬åŠå°é«”å¤±æ•ˆæœ€ç‚ºé‡è¦ã€‚")
    else:
        st.warning("âš ï¸ å°šæœªæ‰¾åˆ° model_comparison.csvï¼Œè«‹å…ˆåŸ·è¡Œ train_upgrade.py")

    # 2. é¡¯ç¤ºåœ–è¡¨ Gallery
    st.subheader("ğŸ“Š è©³ç´°åœ–è¡¨")
    col_a, col_b = st.columns(2)
    
    with col_a:
        st.markdown("**æ··æ·†çŸ©é™£ (Confusion Matrix)**")
        cm_path = os.path.join("reports", "Confusion Matrix.png")
        if os.path.exists(cm_path):
            st.image(cm_path, use_column_width=True)
        else:
            st.info("*(åœ–è¡¨æœªç”Ÿæˆ)*")

        st.markdown("**PR æ›²ç·š (Precision-Recall)**")
        pr_path = os.path.join("reports", "Precision Recall.png")
        if os.path.exists(pr_path):
            st.image(pr_path, use_column_width=True)
        else:
             st.info("*(åœ–è¡¨æœªç”Ÿæˆ)*")

    with col_b:
        st.markdown("**ROC æ›²ç·š (AUC)**")
        auc_path = os.path.join("reports", "AUC.png")
        if os.path.exists(auc_path):
            st.image(auc_path, use_column_width=True)
        else:
            st.info("*(åœ–è¡¨æœªç”Ÿæˆ)*")
            
        st.markdown("**å­¸ç¿’æ›²ç·š (Learning Curve)**")
        lc_path = os.path.join("reports", "Learning Curve.png")
        if os.path.exists(lc_path):
            st.image(lc_path, use_column_width=True)
        else:
             st.info("â„¹ï¸ å­¸ç¿’æ›²ç·šæœªç”Ÿæˆ (å¯èƒ½å·²è·³éæˆ–é‹ç®—ä¸­)")

st.sidebar.info(f"ç•¶å‰ä½¿ç”¨æ¨¡å‹: {model.__class__.__name__ if model else 'æœªè¼‰å…¥'}")